# --- General Configuration ---
# Choose the AI backend to use. Options: "huggingface" or "ollama"
AI_BACKEND="huggingface"

# --- Hugging Face Configuration ---
# Required if AI_BACKEND is "huggingface"
# Get your key from https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY="your_huggingface_api_key_here"

# --- Ollama Configuration ---
# Required if AI_BACKEND is "ollama"
# The host for your local Ollama server, which the `ollama` library will use.
# Defaults to http://localhost:11434 if not set.
OLLAMA_HOST="http://localhost:11434"
# The name of the vision model to use with Ollama (e.g., "llava")
OLLAMA_MODEL="llava"
